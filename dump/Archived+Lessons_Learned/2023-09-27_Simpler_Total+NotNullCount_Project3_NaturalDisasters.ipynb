{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aolda\\OneDrive\\Desktop\\SCS_Modules_ToGitHub\\Project3_Leaflet\\Project3_NaturalDisastersDataReview\\Project3_NaturalDisasters.ipynb\n",
      "c:\\Users\\Aolda\\OneDrive\\Desktop\\SCS_Modules_ToGitHub\\Project3_Leaflet\\Project3_NaturalDisastersDataReview\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Change directory to the directory of current python script. \n",
    "#via URL => https://stackoverflow.com/questions/1432924/python-change-the-scripts-working-directory-to-the-scripts-own-directory\n",
    "#via URL => https://www.geeksforgeeks.org/python-os-path-abspath-method-with-example/\n",
    "\n",
    "file_name = \"Project3_NaturalDisasters.ipynb\"\n",
    "abs_path = os.path.abspath(file_name)        #(__file__)\n",
    "print(abs_path)\n",
    "dir_name = os.path.dirname(abs_path)\n",
    "print(dir_name)\n",
    "print(\"-----\")\n",
    "os.chdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm VAR for location of Resources Folder.\n",
    "target_directory_file1 = \"Resources/DISASTERS/\"\n",
    "source1_file_name = \"1970-2021_DISASTERS.xlsx - emdat data.csv\"\n",
    "\n",
    "Pandas_read_file1 = target_directory_file1 + source1_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Glide</th>\n",
       "      <th>Disaster Group</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Disaster Subsubtype</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>...</th>\n",
       "      <th>No Homeless</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Reconstruction Costs ('000 US$)</th>\n",
       "      <th>Insured Damages ('000 US$)</th>\n",
       "      <th>Total Damages ('000 US$)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Adm Level</th>\n",
       "      <th>Admin1 Code</th>\n",
       "      <th>Admin2 Code</th>\n",
       "      <th>Geo Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-0013-ARG</td>\n",
       "      <td>1970</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-0109-AUS</td>\n",
       "      <td>1970</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ada</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72475.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-0044-BEN</td>\n",
       "      <td>1970</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-0063-BGD</td>\n",
       "      <td>1970</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3648000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-0026-BGD</td>\n",
       "      <td>1970</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Year  Seq Glide Disaster Group Disaster Subgroup  \\\n",
       "0  1970-0013-ARG  1970   13   NaN        Natural      Hydrological   \n",
       "1  1970-0109-AUS  1970  109   NaN        Natural    Meteorological   \n",
       "2  1970-0044-BEN  1970   44   NaN        Natural      Hydrological   \n",
       "3  1970-0063-BGD  1970   63   NaN        Natural    Meteorological   \n",
       "4  1970-0026-BGD  1970   26   NaN        Natural    Meteorological   \n",
       "\n",
       "  Disaster Type  Disaster Subtype Disaster Subsubtype Event Name  ...  \\\n",
       "0         Flood               NaN                 NaN        NaN  ...   \n",
       "1         Storm  Tropical cyclone                 NaN        Ada  ...   \n",
       "2         Flood               NaN                 NaN        NaN  ...   \n",
       "3         Storm  Tropical cyclone                 NaN        NaN  ...   \n",
       "4         Storm               NaN                 NaN        NaN  ...   \n",
       "\n",
       "  No Homeless Total Affected Reconstruction Costs ('000 US$)  \\\n",
       "0         NaN            NaN                             NaN   \n",
       "1         NaN            NaN                             NaN   \n",
       "2         NaN            NaN                             NaN   \n",
       "3         NaN      3648000.0                             NaN   \n",
       "4         NaN          110.0                             NaN   \n",
       "\n",
       "  Insured Damages ('000 US$) Total Damages ('000 US$)        CPI Adm Level  \\\n",
       "0                        NaN                  25000.0  15.001282       NaN   \n",
       "1                        NaN                  72475.0  15.001282       NaN   \n",
       "2                        NaN                    200.0  15.001282       NaN   \n",
       "3                        NaN                  86400.0  15.001282       NaN   \n",
       "4                        NaN                      NaN  15.001282       NaN   \n",
       "\n",
       "  Admin1 Code Admin2 Code Geo Locations  \n",
       "0         NaN         NaN           NaN  \n",
       "1         NaN         NaN           NaN  \n",
       "2         NaN         NaN           NaN  \n",
       "3         NaN         NaN           NaN  \n",
       "4         NaN         NaN           NaN  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a Pandas DataFrame. Reminder pd.read_csv() is targeted to current working directory.\n",
    "\n",
    "#usecols_file1 = [] #Note1 => Will load all Cols to start ... good feature for future if we'd already know the data, etc.\n",
    "#Approach via URL => https://www.datacamp.com/tutorial/pandas-read-csv\n",
    "index_col_file1 = \"Dis No\"\n",
    "\n",
    "natural_disasters_df = pd.read_csv(Pandas_read_file1) #, index_col=index_col_file1)  #SeeNote1+Error below ... dropping the index assignment for now ...  , usecols=usecols_file1)\n",
    "natural_disasters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14644 entries, 0 to 14643\n",
      "Data columns (total 47 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Dis No                           14644 non-null  object \n",
      " 1   Year                             14644 non-null  int64  \n",
      " 2   Seq                              14644 non-null  int64  \n",
      " 3   Glide                            1581 non-null   object \n",
      " 4   Disaster Group                   14644 non-null  object \n",
      " 5   Disaster Subgroup                14644 non-null  object \n",
      " 6   Disaster Type                    14644 non-null  object \n",
      " 7   Disaster Subtype                 11897 non-null  object \n",
      " 8   Disaster Subsubtype              1044 non-null   object \n",
      " 9   Event Name                       3645 non-null   object \n",
      " 10  Country                          14644 non-null  object \n",
      " 11  ISO                              14644 non-null  object \n",
      " 12  Region                           14644 non-null  object \n",
      " 13  Continent                        14644 non-null  object \n",
      " 14  Location                         13298 non-null  object \n",
      " 15  Origin                           3780 non-null   object \n",
      " 16  Associated Dis                   3232 non-null   object \n",
      " 17  Associated Dis2                  698 non-null    object \n",
      " 18  OFDA Response                    1450 non-null   object \n",
      " 19  Appeal                           2440 non-null   object \n",
      " 20  Declaration                      3127 non-null   object \n",
      " 21  Aid Contribution                 677 non-null    float64\n",
      " 22  Dis Mag Value                    4569 non-null   float64\n",
      " 23  Dis Mag Scale                    13571 non-null  object \n",
      " 24  Latitude                         2331 non-null   object \n",
      " 25  Longitude                        2335 non-null   object \n",
      " 26  Local Time                       765 non-null    object \n",
      " 27  River Basin                      1285 non-null   object \n",
      " 28  Start Year                       14644 non-null  int64  \n",
      " 29  Start Month                      14376 non-null  float64\n",
      " 30  Start Day                        11577 non-null  float64\n",
      " 31  End Year                         14644 non-null  int64  \n",
      " 32  End Month                        14095 non-null  float64\n",
      " 33  End Day                          11650 non-null  float64\n",
      " 34  Total Deaths                     10199 non-null  float64\n",
      " 35  No Injured                       3651 non-null   float64\n",
      " 36  No Affected                      8846 non-null   float64\n",
      " 37  No Homeless                      2249 non-null   float64\n",
      " 38  Total Affected                   11041 non-null  float64\n",
      " 39  Reconstruction Costs ('000 US$)  31 non-null     float64\n",
      " 40  Insured Damages ('000 US$)       1094 non-null   float64\n",
      " 41  Total Damages ('000 US$)         4863 non-null   float64\n",
      " 42  CPI                              14329 non-null  float64\n",
      " 43  Adm Level                        7855 non-null   object \n",
      " 44  Admin1 Code                      4581 non-null   object \n",
      " 45  Admin2 Code                      3965 non-null   object \n",
      " 46  Geo Locations                    7855 non-null   object \n",
      "dtypes: float64(15), int64(4), object(28)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get a brief summary of the crowdfunding_info DataFrame.\n",
    "natural_disasters_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dis No', 'Year', 'Seq', 'Glide', 'Disaster Group', 'Disaster Subgroup',\n",
       "       'Disaster Type', 'Disaster Subtype', 'Disaster Subsubtype',\n",
       "       'Event Name', 'Country', 'ISO', 'Region', 'Continent', 'Location',\n",
       "       'Origin', 'Associated Dis', 'Associated Dis2', 'OFDA Response',\n",
       "       'Appeal', 'Declaration', 'Aid Contribution', 'Dis Mag Value',\n",
       "       'Dis Mag Scale', 'Latitude', 'Longitude', 'Local Time', 'River Basin',\n",
       "       'Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month',\n",
       "       'End Day', 'Total Deaths', 'No Injured', 'No Affected', 'No Homeless',\n",
       "       'Total Affected', 'Reconstruction Costs ('000 US$)',\n",
       "       'Insured Damages ('000 US$)', 'Total Damages ('000 US$)', 'CPI',\n",
       "       'Adm Level', 'Admin1 Code', 'Admin2 Code', 'Geo Locations'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List columns in total.\n",
    "\n",
    "natural_disasters_df_colums = natural_disasters_df.columns\n",
    "\n",
    "natural_disasters_df_colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Damages ('000 US$)</th>\n",
       "      <th>Total Deaths</th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Disaster Group</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Location</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2021-0449-YEM</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>Western Asia</td>\n",
       "      <td>Dhamar, Amran, Al Mahwit, Marib, Ibb, Sanaâ€™a C...</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>75000.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2021-0075-ZAF</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Southern Africa</td>\n",
       "      <td>Mpumalanga Province, Free State Province and t...</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14641</th>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>2021-0599-COD</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Biological</td>\n",
       "      <td>Epidemic</td>\n",
       "      <td>Congo (the Democratic Republic of the)</td>\n",
       "      <td>Middle Africa</td>\n",
       "      <td>Tshopo province</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14642</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-0020-SRB</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>Southern Europe</td>\n",
       "      <td>Zitoradja (Toplicki), Doljevac (Nisavski) , Di...</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021-0481-SSD</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>South Sudan</td>\n",
       "      <td>Northern Africa</td>\n",
       "      <td>Mayendit County (Unity); Ayod, Fangak Counties...</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total Damages ('000 US$)  Total Deaths         Dis No Disaster Group  \\\n",
       "14639                       NaN          11.0  2021-0449-YEM        Natural   \n",
       "14640                   75000.0          31.0  2021-0075-ZAF        Natural   \n",
       "14641                       NaN         131.0  2021-0599-COD        Natural   \n",
       "14642                       NaN           NaN  2021-0020-SRB        Natural   \n",
       "14643                       NaN           7.0  2021-0481-SSD        Natural   \n",
       "\n",
       "      Disaster Subgroup Disaster Type                                 Country  \\\n",
       "14639      Hydrological         Flood                                   Yemen   \n",
       "14640      Hydrological         Flood                            South Africa   \n",
       "14641        Biological      Epidemic  Congo (the Democratic Republic of the)   \n",
       "14642      Hydrological         Flood                                  Serbia   \n",
       "14643      Hydrological         Flood                             South Sudan   \n",
       "\n",
       "                Region                                           Location  \\\n",
       "14639     Western Asia  Dhamar, Amran, Al Mahwit, Marib, Ibb, Sanaâ€™a C...   \n",
       "14640  Southern Africa  Mpumalanga Province, Free State Province and t...   \n",
       "14641    Middle Africa                                    Tshopo province   \n",
       "14642  Southern Europe  Zitoradja (Toplicki), Doljevac (Nisavski) , Di...   \n",
       "14643  Northern Africa  Mayendit County (Unity); Ayod, Fangak Counties...   \n",
       "\n",
       "      Continent  \n",
       "14639      Asia  \n",
       "14640    Africa  \n",
       "14641    Africa  \n",
       "14642    Europe  \n",
       "14643    Africa  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an Analysis_DF via Pandas \"select cols\" approach.\n",
    "\n",
    "List_of_Analysis1_Columns = [str(\"Total Damages ('000 US$)\"),'Total Deaths','Dis No','Disaster Group', 'Disaster Subgroup','Disaster Type','Country', 'Region','Location','Continent']\n",
    "     #Note single quotes issue with how Source_File named \"Total Damages ('000 US$)\".\n",
    "\n",
    "Analysis_natural_disasters_df = natural_disasters_df[List_of_Analysis1_Columns] #,]\n",
    "#Reminders via URL => https://www.golinuxcloud.com/pandas-select-columns-examples/ and https://www.datacamp.com/tutorial/python-select-columns\n",
    "\n",
    "Analysis_natural_disasters_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Damages ('000 US$)    float64\n",
      "Total Deaths                float64\n",
      "Dis No                       object\n",
      "Disaster Group               object\n",
      "Disaster Subgroup            object\n",
      "Disaster Type                object\n",
      "Country                      object\n",
      "Region                       object\n",
      "Location                     object\n",
      "Continent                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Print Analysis_DF Data Types to Enable Analysis.\n",
    "\n",
    "print(Analysis_natural_disasters_df.dtypes)\n",
    "#via URL syntax note ... no \"()\" with dtypes ... => https://datatofish.com/data-type-pandas-dataframe/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14644 entries, 0 to 14643\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Total Damages ('000 US$)  4863 non-null   float64\n",
      " 1   Total Deaths              10199 non-null  float64\n",
      " 2   Dis No                    14644 non-null  object \n",
      " 3   Disaster Group            14644 non-null  object \n",
      " 4   Disaster Subgroup         14644 non-null  object \n",
      " 5   Disaster Type             14644 non-null  object \n",
      " 6   Country                   14644 non-null  object \n",
      " 7   Region                    14644 non-null  object \n",
      " 8   Location                  13298 non-null  object \n",
      " 9   Continent                 14644 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Convert Analysis_DF Data Types to Enable Analysis.\n",
    "\n",
    "#N/A ... the Damages and Deaths actually read-in as float64.\n",
    "\n",
    "Analysis_natural_disasters_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish Unique lists of potential visualization columns.\n",
    "\n",
    "Disaster_groups = pd.Series(Analysis_natural_disasters_df[List_of_Analysis1_Columns[3]].unique().tolist())\n",
    "Disaster_subgroups = pd.Series(Analysis_natural_disasters_df[List_of_Analysis1_Columns[4]].unique().tolist())\n",
    "Disaster_types = pd.Series(Analysis_natural_disasters_df[List_of_Analysis1_Columns[5]].unique().tolist())\n",
    "Disaster_countries = pd.Series(Analysis_natural_disasters_df[List_of_Analysis1_Columns[6]].unique().tolist())\n",
    "Disaster_region = pd.Series(Analysis_natural_disasters_df[List_of_Analysis1_Columns[7]].unique().tolist())\n",
    "Diasaster_contenent = pd.Series(Analysis_natural_disasters_df[List_of_Analysis1_Columns[9]].unique().tolist())\n",
    "Disaster_location = pd.Series(Analysis_natural_disasters_df[List_of_Analysis1_Columns[8]].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                  Mendoza\n",
      "1                                               Queensland\n",
      "2                                           Atacora region\n",
      "3                                       Khulna, Chittagong\n",
      "4                                                      NaN\n",
      "                               ...                        \n",
      "11991    Dhamar, Amran, Al Mahwit, Marib, Ibb, Sanaâ€™a C...\n",
      "11992    Mpumalanga Province, Free State Province and t...\n",
      "11993                                      Tshopo province\n",
      "11994    Zitoradja (Toplicki), Doljevac (Nisavski) , Di...\n",
      "11995    Mayendit County (Unity); Ayod, Fangak Counties...\n",
      "Length: 11996, dtype: object\n",
      "------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Americas\n",
       "1     Oceania\n",
       "2      Africa\n",
       "3        Asia\n",
       "4      Europe\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print test lists to validate output.\n",
    "\n",
    "print(Disaster_location)\n",
    "print(\"------\")\n",
    "Diasaster_contenent.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-0013-ARG</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-0109-AUS</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-0044-BEN</td>\n",
       "      <td>1970</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-0063-BGD</td>\n",
       "      <td>1970</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-0026-BGD</td>\n",
       "      <td>1970</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>2021-0449-YEM</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>2021-0075-ZAF</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14641</th>\n",
       "      <td>2021-0599-COD</td>\n",
       "      <td>2021</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14642</th>\n",
       "      <td>2021-0020-SRB</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14643</th>\n",
       "      <td>2021-0481-SSD</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14644 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dis No  Start Year  Start Month  Start Day  End Year  End Month  \\\n",
       "0      1970-0013-ARG        1970          1.0        4.0      1970        1.0   \n",
       "1      1970-0109-AUS        1970          1.0        NaN      1970        1.0   \n",
       "2      1970-0044-BEN        1970          9.0        NaN      1970        9.0   \n",
       "3      1970-0063-BGD        1970         11.0       12.0      1970       11.0   \n",
       "4      1970-0026-BGD        1970          4.0       13.0      1970        4.0   \n",
       "...              ...         ...          ...        ...       ...        ...   \n",
       "14639  2021-0449-YEM        2021          7.0       16.0      2021        8.0   \n",
       "14640  2021-0075-ZAF        2021          2.0        1.0      2021        2.0   \n",
       "14641  2021-0599-COD        2021          9.0        7.0      2021        9.0   \n",
       "14642  2021-0020-SRB        2021          1.0       11.0      2021        1.0   \n",
       "14643  2021-0481-SSD        2021          5.0        NaN      2021       10.0   \n",
       "\n",
       "       End Day  \n",
       "0          4.0  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3         12.0  \n",
       "4         13.0  \n",
       "...        ...  \n",
       "14639      7.0  \n",
       "14640     15.0  \n",
       "14641     13.0  \n",
       "14642     12.0  \n",
       "14643      7.0  \n",
       "\n",
       "[14644 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Date Observations and Date Durations DataFrame\n",
    "\n",
    "List_of_Dates1_Columns = ['Dis No', 'Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month','End Day' ]\n",
    "\n",
    "Disaster_dates_df = natural_disasters_df[List_of_Dates1_Columns]\n",
    "\n",
    "Disaster_dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>Start Month</th>\n",
       "      <th>Start Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970-0013-ARG</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970-0109-AUS</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970-0044-BEN</td>\n",
       "      <td>1970</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970-0063-BGD</td>\n",
       "      <td>1970</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970-0026-BGD</td>\n",
       "      <td>1970</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dis No  Start Year  Start Month  Start Day\n",
       "0  1970-0013-ARG        1970          1.0        4.0\n",
       "1  1970-0109-AUS        1970          1.0        NaN\n",
       "2  1970-0044-BEN        1970          9.0        NaN\n",
       "3  1970-0063-BGD        1970         11.0       12.0\n",
       "4  1970-0026-BGD        1970          4.0       13.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Year Starting Date Column\n",
    "\n",
    "Disaster_starting_dates_df = Disaster_dates_df.copy()\n",
    "Starting_date_cols = ['Dis No', 'Start Year', 'Start Month', 'Start Day']\n",
    "Disaster_starting_dates_df = Disaster_starting_dates_df.loc[:,Starting_date_cols]\n",
    "\n",
    "#Print to validate.\n",
    "Disaster_starting_dates_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dis No</th>\n",
       "      <th>End Year</th>\n",
       "      <th>End Month</th>\n",
       "      <th>End Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>2021-0449-YEM</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14640</th>\n",
       "      <td>2021-0075-ZAF</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14641</th>\n",
       "      <td>2021-0599-COD</td>\n",
       "      <td>2021</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14642</th>\n",
       "      <td>2021-0020-SRB</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14643</th>\n",
       "      <td>2021-0481-SSD</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dis No  End Year  End Month  End Day\n",
       "14639  2021-0449-YEM      2021        8.0      7.0\n",
       "14640  2021-0075-ZAF      2021        2.0     15.0\n",
       "14641  2021-0599-COD      2021        9.0     13.0\n",
       "14642  2021-0020-SRB      2021        1.0     12.0\n",
       "14643  2021-0481-SSD      2021       10.0      7.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Year Ending Date Column\n",
    "Disaster_ending_dates_df = Disaster_dates_df.copy()\n",
    "\n",
    "#Reduce copied DF to necessary columns for analysis.\n",
    "Ending_date_cols = ['Dis No', 'End Year', 'End Month', 'End Day']\n",
    "Disaster_ending_dates_df = Disaster_ending_dates_df.loc[:,Ending_date_cols]\n",
    "\n",
    "#Print to validate.\n",
    "Disaster_ending_dates_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4.0\n",
      "1         NaN\n",
      "2         NaN\n",
      "3        12.0\n",
      "4        13.0\n",
      "         ... \n",
      "14639    16.0\n",
      "14640     1.0\n",
      "14641     7.0\n",
      "14642    11.0\n",
      "14643     NaN\n",
      "Name: Start Day, Length: 14644, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#New Approach => https://chartio.com/resources/tutorials/how-to-check-if-any-value-is-nan-in-a-pandas-dataframe/\n",
    "#Support URL => https://stackoverflow.com/questions/19844985/pandas-selecting-array-of-index-labels-with-loc\n",
    "#Support URL2 => https://stackoverflow.com/questions/19155718/select-pandas-rows-based-on-list-index#:~:text=Use.iloc%20for%20integer%20based%20indexing%20and.loc%20for%20label,below%20example%3A%20ind_list%20%3D%20%5B1%2C%203%5D%20df.iloc%20%5Bind_list%5D\n",
    "\n",
    "StartYear_Index = Starting_date_cols.index('Start Year')\n",
    "StartMonth_Index = Starting_date_cols.index('Start Month')\n",
    "StartDay_Index = Starting_date_cols.index('Start Day')\n",
    "#Above via URL => https://stackoverflow.com/questions/176918/finding-the-index-of-an-item-in-a-list\n",
    "\n",
    "#Strt_day_nulls = pd.Series([Disaster_starting_dates_df.index.isin([StartDay_Index])]) # .loc['Start Day']])\n",
    "#WEIRDLY produced a true/false list .... \n",
    "\n",
    "st_d = Disaster_starting_dates_df['Start Day']\n",
    "print(st_d)\n",
    "\n",
    "\n",
    "#NEED to figure out how to get this working ... for our date duration analysis ... to be solid ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Dis No         1970-0013-ARG\n",
      "Start Year       ...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#NOT WORKING ....\n",
    "#Cleaed up via URL => https://stackoverflow.com/questions/64979067/how-do-i-properly-use-iloc-indexing\n",
    "#2nd URL reference => https://stackoverflow.com/questions/31593201/how-are-iloc-and-loc-different\n",
    "\n",
    "Date_DF_Total_Rows_Array = pd.Series(list([Disaster_dates_df.iloc[0]]))\n",
    "print(Date_DF_Total_Rows_Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aolda\\OneDrive\\Desktop\\SCS_Modules_ToGitHub\\Project3_Leaflet\\Project3_NaturalDisastersDataReview\\Project3_NaturalDisasters.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Use NumPy to Confirm total NaNs within the Date DataSets. To determine the impact of removing them entirely vs replacing with a placeholder (IE: something that would require a team discussion ... because of the potential \"false\" data impact on the visualiztion).\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#Count Approach via URL => https://www.statology.org/numpy-count-nan/\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m Date_DF_Total_Rows \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcount_nonzero(\u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(Disaster_ending_dates_df\u001b[39m.\u001b[39miloc[:\u001b[39m0\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m Date_DF_Total_Rows\n",
      "File \u001b[1;32mc:\\Users\\Aolda\\anaconda3\\envs\\dev\\Lib\\site-packages\\pandas\\core\\generic.py:2113\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2109\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   2110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2111\u001b[0m     \u001b[39mself\u001b[39m, ufunc: np\u001b[39m.\u001b[39mufunc, method: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39minputs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[0;32m   2112\u001b[0m ):\n\u001b[1;32m-> 2113\u001b[0m     \u001b[39mreturn\u001b[39;00m arraylike\u001b[39m.\u001b[39marray_ufunc(\u001b[39mself\u001b[39m, ufunc, method, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aolda\\anaconda3\\envs\\dev\\Lib\\site-packages\\pandas\\core\\arraylike.py:410\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__call__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs:\n\u001b[0;32m    406\u001b[0m     \u001b[39m# for np.<ufunc>(..) calls\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     \u001b[39m# kwargs cannot necessarily be handled block-by-block, so only\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[39m# take this path if there are no kwargs\u001b[39;00m\n\u001b[0;32m    409\u001b[0m     mgr \u001b[39m=\u001b[39m inputs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m--> 410\u001b[0m     result \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39mapply(\u001b[39mgetattr\u001b[39m(ufunc, method))\n\u001b[0;32m    411\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[39m# otherwise specific ufunc methods (eg np.<ufunc>.accumulate(..))\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[39m# Those can have an axis keyword and thus can't be called block-by-block\u001b[39;00m\n\u001b[0;32m    414\u001b[0m     result \u001b[39m=\u001b[39m default_array_ufunc(inputs[\u001b[39m0\u001b[39m], ufunc, method, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aolda\\anaconda3\\envs\\dev\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:350\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(f):\n\u001b[1;32m--> 350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Aolda\\anaconda3\\envs\\dev\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:351\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m    346\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Block]:\n\u001b[0;32m    347\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[39m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[39m    one\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_op_result(result)\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "#Use NumPy to Confirm total NaNs within the Date DataSets. To determine the impact of removing them entirely vs replacing with a placeholder (IE: something that would require a team discussion ... because of the potential \"false\" data impact on the visualiztion).\n",
    "\n",
    "#Count Approach via URL => https://www.statology.org/numpy-count-nan/\n",
    "\n",
    "Date_DF_Total_Rows = np.count_nonzero(~np.isnan(Disaster_ending_dates_df.iloc[:0]))\n",
    "\n",
    "Date_DF_Total_Rows\n",
    "#Start_Year_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14644 entries, 0 to 14643\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Dis No       14644 non-null  object \n",
      " 1   Start Year   14644 non-null  int64  \n",
      " 2   Start Month  14376 non-null  float64\n",
      " 3   Start Day    11577 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 457.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14644 entries, 0 to 14643\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Dis No     14644 non-null  object \n",
      " 1   End Year   14644 non-null  int64  \n",
      " 2   End Month  14095 non-null  float64\n",
      " 3   End Day    11650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 457.8+ KB\n",
      "+-+-+-+-+-+\n",
      "The NaNs Analysis is below:\n",
      "Starting_Dates:\n",
      "None\n",
      "Ending_Dates:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#DEPRECATED APPROACH .... \n",
    "#\n",
    "#Determine how man NaNs are contained within both DFs.\n",
    "\n",
    "#NaNs_Starting_dates = Disaster_starting_dates_df.info()\n",
    "#NaNs_Ending_dates = Disaster_ending_dates_df.info()\n",
    "\n",
    "#print(\"+-+-+-+-+-+\")\n",
    "#print(f\"The NaNs Analysis is below:\\nStarting_Dates:\\n{NaNs_Starting_dates}\\nEnding_Dates:\\n{NaNs_Ending_dates}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#RENAME COLS approach:\n",
    "\n",
    "#new = {\n",
    "#    'blurb': 'description',\n",
    "#    'launched_at': 'launched_date',\n",
    "#    'deadline': 'end_date'\n",
    "#}\n",
    "\n",
    "#campaign_df_new = campaign_df.rename(columns=new)\n",
    "#campaign_df_new.head()\n",
    "\n",
    "#\n",
    "#DateTime Approach 1\n",
    "\n",
    "#from datetime import datetime as dt\n",
    "\n",
    "#campaign_df_new2 = campaign_df_new.copy()\n",
    "\n",
    "#campaign_df_new2['launched_date'] = pd.to_datetime(campaign_df_new2['launched_date'], unit='s').dt.strftime('%Y-%m-%d')\n",
    "#campaign_df_new2['end_date'] = pd.to_datetime(campaign_df_new2['end_date'], unit='s').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#\n",
    "#DateTime Approach 2\n",
    "#DateInsert_Month_Year_DF = pd.Series(pd.to_datetime(Housing_Prices_by_year_df['month_Year'], format='%Y-%m-%d', errors = 'coerce'))\n",
    "\n",
    "#\n",
    "#DateTime Approach 3 ... if no \"day = 1\" provided to strip it out ... of your yyyy-mm formated convert.\n",
    "#HP_Month_Year_DF = DateClean_Housing_Prices_by_year_df['OLD_AsTXT_month_Year'].str.split('-')\n",
    "#HP_Year_Row = HP_Month_Year_DF.str.get(0) #access the first element for eventual \"column1\"\n",
    "#HP_Month_Row = HP_Month_Year_DF.str.get(1) #access the 2nd element for eventual \"column2\"\n",
    "#HP_Day_Row = HP_Month_Year_DF.str.get(2) #access the 3rd element for eventual \"column3\"\n",
    "\n",
    "#\n",
    "#Merge Appproach\n",
    "#Manual_Merge_Geo = pd.concat([Geo_CityRow,Geo_ProvRow], axis=1)\n",
    "\n",
    "#+ RENAME cols right away in script order.\n",
    "#Manual_Merge_Geo.columns.values[0] = \"City_Region\"\n",
    "#Manual_Merge_Geo.columns.values[1] = \"Province\"\n",
    "\n",
    "#\n",
    "#Merge 2\n",
    "#GeoUpdated_DF = pd.concat([reduced_main_renamed_df,Manual_Merge_Geo],axis=1,join='outer') # ,join_axes=None,ignore_index=False)\n",
    "#print(GeoUpdated_DF)\n",
    "\n",
    "#\n",
    "#REMOVE \"bad data\" for our Analysis purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
