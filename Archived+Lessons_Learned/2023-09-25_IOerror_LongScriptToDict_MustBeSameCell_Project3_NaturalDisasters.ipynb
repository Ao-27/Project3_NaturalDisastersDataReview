{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aolda\\OneDrive\\Desktop\\SCS_Modules_ToGitHub\\Project3_Leaflet\\Project3_NaturalDisastersDataReview\\Project3_NaturalDisasters.ipynb\n",
      "c:\\Users\\Aolda\\OneDrive\\Desktop\\SCS_Modules_ToGitHub\\Project3_Leaflet\\Project3_NaturalDisastersDataReview\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Change directory to the directory of current python script. \n",
    "#via URL => https://stackoverflow.com/questions/1432924/python-change-the-scripts-working-directory-to-the-scripts-own-directory\n",
    "#via URL => https://www.geeksforgeeks.org/python-os-path-abspath-method-with-example/\n",
    "\n",
    "file_name = \"Project3_NaturalDisasters.ipynb\"\n",
    "abs_path = os.path.abspath(file_name)        #(__file__)\n",
    "print(abs_path)\n",
    "dir_name = os.path.dirname(abs_path)\n",
    "print(dir_name)\n",
    "print(\"-----\")\n",
    "os.chdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm VAR for location of Resources Folder.\n",
    "target_directory_file1 = \"Resources/DISASTERS/\"\n",
    "source1_file_name = \"1970-2021_DISASTERS.xlsx - emdat data.csv\"\n",
    "\n",
    "Pandas_read_file1 = target_directory_file1 + source1_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Glide</th>\n",
       "      <th>Disaster Group</th>\n",
       "      <th>Disaster Subgroup</th>\n",
       "      <th>Disaster Type</th>\n",
       "      <th>Disaster Subtype</th>\n",
       "      <th>Disaster Subsubtype</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>...</th>\n",
       "      <th>No Homeless</th>\n",
       "      <th>Total Affected</th>\n",
       "      <th>Reconstruction Costs ('000 US$)</th>\n",
       "      <th>Insured Damages ('000 US$)</th>\n",
       "      <th>Total Damages ('000 US$)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Adm Level</th>\n",
       "      <th>Admin1 Code</th>\n",
       "      <th>Admin2 Code</th>\n",
       "      <th>Geo Locations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dis No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-0013-ARG</th>\n",
       "      <td>1970</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-0109-AUS</th>\n",
       "      <td>1970</td>\n",
       "      <td>109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Australia</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72475.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-0044-BEN</th>\n",
       "      <td>1970</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Hydrological</td>\n",
       "      <td>Flood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Benin</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-0063-BGD</th>\n",
       "      <td>1970</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Tropical cyclone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3648000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-0026-BGD</th>\n",
       "      <td>1970</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural</td>\n",
       "      <td>Meteorological</td>\n",
       "      <td>Storm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.001282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year  Seq Glide Disaster Group Disaster Subgroup Disaster Type  \\\n",
       "Dis No                                                                          \n",
       "1970-0013-ARG  1970   13   NaN        Natural      Hydrological         Flood   \n",
       "1970-0109-AUS  1970  109   NaN        Natural    Meteorological         Storm   \n",
       "1970-0044-BEN  1970   44   NaN        Natural      Hydrological         Flood   \n",
       "1970-0063-BGD  1970   63   NaN        Natural    Meteorological         Storm   \n",
       "1970-0026-BGD  1970   26   NaN        Natural    Meteorological         Storm   \n",
       "\n",
       "               Disaster Subtype Disaster Subsubtype Event Name     Country  \\\n",
       "Dis No                                                                       \n",
       "1970-0013-ARG               NaN                 NaN        NaN   Argentina   \n",
       "1970-0109-AUS  Tropical cyclone                 NaN        Ada   Australia   \n",
       "1970-0044-BEN               NaN                 NaN        NaN       Benin   \n",
       "1970-0063-BGD  Tropical cyclone                 NaN        NaN  Bangladesh   \n",
       "1970-0026-BGD               NaN                 NaN        NaN  Bangladesh   \n",
       "\n",
       "               ... No Homeless Total Affected Reconstruction Costs ('000 US$)  \\\n",
       "Dis No         ...                                                              \n",
       "1970-0013-ARG  ...         NaN            NaN                             NaN   \n",
       "1970-0109-AUS  ...         NaN            NaN                             NaN   \n",
       "1970-0044-BEN  ...         NaN            NaN                             NaN   \n",
       "1970-0063-BGD  ...         NaN      3648000.0                             NaN   \n",
       "1970-0026-BGD  ...         NaN          110.0                             NaN   \n",
       "\n",
       "              Insured Damages ('000 US$) Total Damages ('000 US$)        CPI  \\\n",
       "Dis No                                                                         \n",
       "1970-0013-ARG                        NaN                  25000.0  15.001282   \n",
       "1970-0109-AUS                        NaN                  72475.0  15.001282   \n",
       "1970-0044-BEN                        NaN                    200.0  15.001282   \n",
       "1970-0063-BGD                        NaN                  86400.0  15.001282   \n",
       "1970-0026-BGD                        NaN                      NaN  15.001282   \n",
       "\n",
       "              Adm Level Admin1 Code Admin2 Code Geo Locations  \n",
       "Dis No                                                         \n",
       "1970-0013-ARG       NaN         NaN         NaN           NaN  \n",
       "1970-0109-AUS       NaN         NaN         NaN           NaN  \n",
       "1970-0044-BEN       NaN         NaN         NaN           NaN  \n",
       "1970-0063-BGD       NaN         NaN         NaN           NaN  \n",
       "1970-0026-BGD       NaN         NaN         NaN           NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a Pandas DataFrame. Reminder pd.read_csv() is targeted to current working directory.\n",
    "\n",
    "#usecols_file1 = [] #Note1 => Will load all Cols to start ... good feature for future if we'd already know the data, etc.\n",
    "#Approach via URL => https://www.datacamp.com/tutorial/pandas-read-csv\n",
    "index_col_file1 = \"Dis No\"\n",
    "\n",
    "natural_disasters_df = pd.read_csv(Pandas_read_file1, index_col=index_col_file1)  #SeeNote1 , usecols=usecols_file1)\n",
    "natural_disasters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14644 entries, 1970-0013-ARG to 2021-0481-SSD\n",
      "Data columns (total 46 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Year                             14644 non-null  int64  \n",
      " 1   Seq                              14644 non-null  int64  \n",
      " 2   Glide                            1581 non-null   object \n",
      " 3   Disaster Group                   14644 non-null  object \n",
      " 4   Disaster Subgroup                14644 non-null  object \n",
      " 5   Disaster Type                    14644 non-null  object \n",
      " 6   Disaster Subtype                 11897 non-null  object \n",
      " 7   Disaster Subsubtype              1044 non-null   object \n",
      " 8   Event Name                       3645 non-null   object \n",
      " 9   Country                          14644 non-null  object \n",
      " 10  ISO                              14644 non-null  object \n",
      " 11  Region                           14644 non-null  object \n",
      " 12  Continent                        14644 non-null  object \n",
      " 13  Location                         13298 non-null  object \n",
      " 14  Origin                           3780 non-null   object \n",
      " 15  Associated Dis                   3232 non-null   object \n",
      " 16  Associated Dis2                  698 non-null    object \n",
      " 17  OFDA Response                    1450 non-null   object \n",
      " 18  Appeal                           2440 non-null   object \n",
      " 19  Declaration                      3127 non-null   object \n",
      " 20  Aid Contribution                 677 non-null    float64\n",
      " 21  Dis Mag Value                    4569 non-null   float64\n",
      " 22  Dis Mag Scale                    13571 non-null  object \n",
      " 23  Latitude                         2331 non-null   object \n",
      " 24  Longitude                        2335 non-null   object \n",
      " 25  Local Time                       765 non-null    object \n",
      " 26  River Basin                      1285 non-null   object \n",
      " 27  Start Year                       14644 non-null  int64  \n",
      " 28  Start Month                      14376 non-null  float64\n",
      " 29  Start Day                        11577 non-null  float64\n",
      " 30  End Year                         14644 non-null  int64  \n",
      " 31  End Month                        14095 non-null  float64\n",
      " 32  End Day                          11650 non-null  float64\n",
      " 33  Total Deaths                     10199 non-null  float64\n",
      " 34  No Injured                       3651 non-null   float64\n",
      " 35  No Affected                      8846 non-null   float64\n",
      " 36  No Homeless                      2249 non-null   float64\n",
      " 37  Total Affected                   11041 non-null  float64\n",
      " 38  Reconstruction Costs ('000 US$)  31 non-null     float64\n",
      " 39  Insured Damages ('000 US$)       1094 non-null   float64\n",
      " 40  Total Damages ('000 US$)         4863 non-null   float64\n",
      " 41  CPI                              14329 non-null  float64\n",
      " 42  Adm Level                        7855 non-null   object \n",
      " 43  Admin1 Code                      4581 non-null   object \n",
      " 44  Admin2 Code                      3965 non-null   object \n",
      " 45  Geo Locations                    7855 non-null   object \n",
      "dtypes: float64(15), int64(4), object(27)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get a brief summary of the crowdfunding_info DataFrame.\n",
    "natural_disasters_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Data Check - CSV reader headers are: ['Dis No', 'Year', 'Seq', 'Glide', 'Disaster Group', 'Disaster Subgroup', 'Disaster Type', 'Disaster Subtype', 'Disaster Subsubtype', 'Event Name', 'Country', 'ISO', 'Region', 'Continent', 'Location', 'Origin', 'Associated Dis', 'Associated Dis2', 'OFDA Response', 'Appeal', 'Declaration', 'Aid Contribution', 'Dis Mag Value', 'Dis Mag Scale', 'Latitude', 'Longitude', 'Local Time', 'River Basin', 'Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month', 'End Day', 'Total Deaths', 'No Injured', 'No Affected', 'No Homeless', 'Total Affected', \"Reconstruction Costs ('000 US$)\", \"Insured Damages ('000 US$)\", \"Total Damages ('000 US$)\", 'CPI', 'Adm Level', 'Admin1 Code', 'Admin2 Code', 'Geo Locations']\n",
      "The width of the CSV is : 47\n",
      "+-------+\n"
     ]
    }
   ],
   "source": [
    "#AoPers => use For Loop to create a Dict for specific column data that we'd like to manipulate to enable the visualizations. Goal with below to to enable data analysis to become easier via List/dict Comprehension functionalities. Objective is to save memory via those python functions as well as add code clarity.\n",
    "\n",
    "with open(Pandas_read_file1, 'r',encoding='utf-8-sig',newline='') as csv_file1:\n",
    "     csv_reader1 = csv.reader(csv_file1,delimiter=\",\")\n",
    "     \n",
    "#Create Exploratory analysis for the Header Row to assess the .csv file width (IE: how many raw_sourcedata_columns)\n",
    "     header_file1 = next(csv_file1).strip().split(\",\")\n",
    "     csv1_width = len(header_file1)\n",
    "     print(f\"Test - Data Check - CSV reader headers are: {header_file1}\") #PRODUCES a list ... which can be a VAR[0] or VAR[1] to leverage ... \n",
    "     print(f\"The width of the CSV is : {csv1_width}\") #via => https://www.freecodecamp.org/news/python-f-strings-tutorial-how-to-use-f-strings-for-string-formatting/\n",
    "     print(\"+-------+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform header Var into list of Indexes for quicker fetching.\n",
    "#via URL => https://stackoverflow.com/questions/52097896/find-indices-of-values-in-a-list?rq=3\n",
    "\n",
    "header_file1_colnames = {} ##Name in example for dict is \"indexes\" ... \n",
    "for i, x in enumerate(header_file1):\n",
    "     header_file1_colnames.setdefault(str(x).strip(),[]).append(i) ##See comment above ...  indexes.setdefault(x,[]).append(i)\n",
    "\n",
    "\n",
    "#Pers Note added the following to \"trim\" the source file col_names to enable the \"search_for_i\" ... that I've input below ...  via URL => https://www.askpython.com/python/string/trim-a-string-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dis No': [0], 'Year': [1], 'Seq': [2], 'Glide': [3], 'Disaster Group': [4], 'Disaster Subgroup': [5], 'Disaster Type': [6], 'Disaster Subtype': [7], 'Disaster Subsubtype': [8], 'Event Name': [9], 'Country': [10], 'ISO': [11], 'Region': [12], 'Continent': [13], 'Location': [14], 'Origin': [15], 'Associated Dis': [16], 'Associated Dis2': [17], 'OFDA Response': [18], 'Appeal': [19], 'Declaration': [20], 'Aid Contribution': [21], 'Dis Mag Value': [22], 'Dis Mag Scale': [23], 'Latitude': [24], 'Longitude': [25], 'Local Time': [26], 'River Basin': [27], 'Start Year': [28], 'Start Month': [29], 'Start Day': [30], 'End Year': [31], 'End Month': [32], 'End Day': [33], 'Total Deaths': [34], 'No Injured': [35], 'No Affected': [36], 'No Homeless': [37], 'Total Affected': [38], \"Reconstruction Costs ('000 US$)\": [39], \"Insured Damages ('000 US$)\": [40], \"Total Damages ('000 US$)\": [41], 'CPI': [42], 'Adm Level': [43], 'Admin1 Code': [44], 'Admin2 Code': [45], 'Geo Locations': [46]}\n"
     ]
    }
   ],
   "source": [
    "#test print the header_file1_colnames result.\n",
    "print(header_file1_colnames)\n",
    "\n",
    "#KeyNote ... it delivered the colnames as \"keys\" for the dicts ... the indexes of \"x\" above ... actually became the \"values\" ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing prior URLs approach to use \"indexes.get(i, [])\"\n",
    "#Goal here is to enable me to run the cell with a different value entered to simply deliver the \"index\" ... I need to update the Loop_PlaceHolder script below ... \n",
    "\n",
    "search_for_i = \"Total Damages ('000 US$)\" [41]  #\"Total Deaths\" [34] #\"Start Year\" [28] .. mth [29] .. day [30] ... End Year [31] ... \"end month\" [32] ... \"End day\" [33] ...  #\"Location\" [14]  #\"Continent\" [13]  #\"Region\" [12]   #\"Disaster Group\" [4]  #\"Country\" [10] #SubGroup [5] DisasterType [6]\n",
    "\n",
    "#Code below from prior URL. However, for traceability on understanding it use URL => https://stackoverflow.com/questions/2068349/understanding-get-method-in-python\n",
    "\n",
    "header_file1_colnames.get(search_for_i,[])\n",
    "\n",
    "#Key Note ... while doing this I realize how much \"labour intensive\" it is ... and it would just be best to leverage the natural Panda's functionality ... however, by working in such bad data sets in the past ... I at times would need to manually parse data in this way to ensure of it's accuracy (IE: to enable comparisons to a \"source system\" ... after staff have incorrectly manipulated/extracted the data from the system ... etc. etc.... Cloud focused \"Legacy\" business challenges truly ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Aolda\\OneDrive\\Desktop\\SCS_Modules_ToGitHub\\Project3_Leaflet\\Project3_NaturalDisastersDataReview\\Project3_NaturalDisasters.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Loop_PlaceHolder \u001b[39m=\u001b[39m [] \u001b[39m#List to Append Dict of each col as a \"key\".\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m    \u001b[39m#ADDmore VARs below here if needed once we've completed the first pass of the data.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#Loop through the non-header data rows for analysis enabling columns to populate Records_ForAnalysis Dict as var.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m count,rows_file1 \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(csv_reader1,\u001b[39m1\u001b[39m):  \u001b[39m#via URL => https://stackoverflow.com/questions/28973207/get-length-of-csv-file-without-ruining-reader\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      Records_forAnalysis \u001b[39m=\u001b[39m {}\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Aolda/OneDrive/Desktop/SCS_Modules_ToGitHub/Project3_Leaflet/Project3_NaturalDisastersDataReview/Project3_NaturalDisasters.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m      num_rows \u001b[39m=\u001b[39m count \u001b[39m#Note Enumerate is starting from \"1\" which ensures it's accuracy.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "#IO Error Note => https://stackoverflow.com/questions/18952716/valueerror-i-o-operation-on-closed-file\n",
    "#\n",
    "#\n",
    "#Initialize Variables to extract from the source file data to enable the module 3 outcomes/calculations.\n",
    "Loop_PlaceHolder = [] #List to Append Dict of each col as a \"key\".\n",
    "   #ADDmore VARs below here if needed once we've completed the first pass of the data.\n",
    "\n",
    "#Loop through the non-header data rows for analysis enabling columns to populate Records_ForAnalysis Dict as var.\n",
    "\n",
    "for count,rows_file1 in enumerate(csv_reader1,1):  #via URL => https://stackoverflow.com/questions/28973207/get-length-of-csv-file-without-ruining-reader\n",
    "     Records_forAnalysis = {}\n",
    "\n",
    "     num_rows = count #Note Enumerate is starting from \"1\" which ensures it's accuracy.\n",
    "     Records_forAnalysis.update({\"File1_Row_ID\":num_rows})\n",
    "\n",
    "     Index_col = str(rows_file1[0])\n",
    "     Records_forAnalysis.update({str(header_file1[0]):Index_col})\n",
    "     #Note this is \"Dis No\" ... as per header_file1 .. parsed in the cell above.\n",
    "\n",
    "     Disaster_grp_col = str(rows_file1[4])\n",
    "     Records_forAnalysis.update({str(header_file1[4]):Disaster_grp_col})\n",
    "\n",
    "     Disaster_subgrp_col = str(rows_file1[5])\n",
    "     Records_forAnalysis.update({str(header_file1[5]):Disaster_subgrp_col})\n",
    "\n",
    "     Disaster_type_col = str(rows_file1[6])\n",
    "     Records_forAnalysis.update({str(header_file1[6]):Disaster_type_col})\n",
    "\n",
    "     Country_col = str(rows_file1[10])\n",
    "     Records_forAnalysis.update({str(header_file1[10]):Country_col})\n",
    "\n",
    "     Region_col = str(rows_file1[12])\n",
    "     Records_forAnalysis.update({str(header_file1[12]):Region_col})\n",
    "   \n",
    "     Location_col = str(rows_file1[14])\n",
    "     Records_forAnalysis.update({str(header_file1[14]):Region_col})\n",
    "\n",
    "     Continent_col = str(rows_file1[13])\n",
    "     Records_forAnalysis.update({str(header_file1[13]):Region_col})\n",
    "\n",
    "     TotalDeaths_col = float(rows_file1[12])\n",
    "     Records_forAnalysis.update({str(header_file1[34]):Region_col})\n",
    "\n",
    "     TotalDamages_col = float(rows_file1[12])\n",
    "     Records_forAnalysis.update({str(header_file1[41]):Region_col})\n",
    "\n",
    "#APPEND the Dict to a List ... for eventual Panda's DF consumption + to enable easier column value fetching via key+value consistency.\n",
    "Loop_PlaceHolder.append(Records_forAnalysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print to console to validate observations.\n",
    "print(Loop_PlaceHolder)\n",
    "print(\"+-+-+-+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
